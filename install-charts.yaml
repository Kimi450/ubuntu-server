---
- name: Install basic charts
  hosts: all
  gather_facts: true
  vars:
    namespace_monitoring: monitoring
    namespace_generic_services: generic-services
    namespace_cert_manager: cert-manager
    namespace_ingress: ingress-nginx
    namespace_cloudnative_postgres: "cnpg-system"

    helm_kube_prometheus_stack_loki_config: "" # default

    # The following has been set to disable Truecharts own injection
    # of manifests for SCALE products I believe either way I dont need it:
    # - manifestManager.enabled=false
    helm_common_general: "\
      global.metallb.addServiceAnnotations=false,\
      global.traefik.addServiceAnnotations=false,\
      portal.open.enabled=false,\
      operator.verify.enabled=false,\
      workload.main.type=StatefulSet,\
      podOptions.dnsConfig.nameservers={8.8.8.8,8.8.4.4}"
    
    helm_common_ingress: "\
      ingress.main.enabled=true,\
      ingress.main.primary=true,\
      ingress.main.expandObjectName=true,\
      ingress.main.ingressClassName=nginx,\
      ingress.main.integrations.certManager.enabled=true,\
      ingress.main.integrations.certManager.certificateIssuer=letsencrypt-prod,\
      ingress.main.integrations.traefik.enabled=false,\
      ingress.main.hosts[0].paths[0].path='/',\
      ingress.main.hosts[0].paths[0].pathType='Prefix'"
    
    helm_common_resources: "\
      resources.requests.cpu={{ charts.resources.requests.cpu }},\
      resources.requests.memory={{ charts.resources.requests.memory }},\
      resources.limits.cpu={{ charts.resources.limits.cpu }},\
      resources.limits.memory={{ charts.resources.limits.memory }}"

    # persistence.config.hostPathType=DirectoryOrCreate doesnt work
    # because it creates the dir with root ownership and no write permissions
    helm_common_persistence: "\
      persistence.shared.enabled=false,\
      persistence.shm.enabled=false,\
      persistence.temp.enabled=false,\
      persistence.varlogs.enabled=false"

    helm_common_persistence_config: "\
      persistence.config.enabled=true,\
      persistence.config.type=hostPath"

    # readOnlyRootFilesystem=false is needed for the app to be able to take
    # backups in /config/Backups
    # runAsUser={{ uid }} gives write access on the pod
    helm_common_security_contexts: "\
      securityContext.container.readOnlyRootFilesystem=false,\
      securityContext.container.runAsUser={{ uid }},\
      securityContext.container.runAsGroup=568"

    venv_dir: "{{ basics.home_dir }}/.venv-install-charts"
    venv_python: "{{ venv_dir }}/bin/python3"

  tasks:
    - name: Generate a virtual env with dependences for playbook
      pip:
        name:
          - kubernetes
        virtualenv: "{{ venv_dir }}"
        # On Debian-based systems the correct python*-venv package must
        # be installed to use the `venv` module.
        virtualenv_command: "python3 -m venv"

    - name: "Create host path dir for config"
      file:
        path: "{{ charts.services.configs_dir }}"
        state: directory
        mode: '0777'
      become: true # incase the dirs are created at root level

    - name: Process variable to add disks
      block:
        - name: "Create host path dir"
          file:
            path: "{{ item.host_path }}"
            state: directory
            mode: '0777'
          become: true # incase the dirs are created at root level
          loop: "{{ charts.services.tdarr.persistence }}"
        - name: Set facts
          set_fact:
            helm_common_persistence_cache: >-
              {{- helm_common_persistence_cache | default('')
                  + 'persistence.cache-' + item.name + '.enabled=true,'
                  + 'persistence.cache-' + item.name + '.type=hostPath,'
                  + 'persistence.cache-' + item.name + '.hostPath=' +  item.host_path + ','
                  + 'persistence.cache-' + item.name + '.mountPath=/data/' + item.name + '/cache,'
              -}}
          loop: "{{ charts.services.tdarr.persistence }}"

    - name: Process variable to add disks
      block:
        - name: "Create host path dir"
          file:
            path: "{{ item.host_path }}"
            state: directory
            mode: '0777'
          become: true # incase the dirs are created at root level
          loop: "{{ charts.services.radarr.persistence }}"
        - name: Set facts
          set_fact:
            helm_common_persistence_movies: >-
              {{- helm_common_persistence_movies | default('')
                  + 'persistence.movies-' + item.name + '.enabled=true,'
                  + 'persistence.movies-' + item.name + '.type=hostPath,'
                  + 'persistence.movies-' + item.name + '.hostPath=' +  item.host_path + ','
                  + 'persistence.movies-' + item.name + '.mountPath=/data/' + item.name + '/movies,'
              -}}
          loop: "{{ charts.services.radarr.persistence }}"

    - name: Process variable to add disks
      block:
        - name: "Create host path dir"
          file:
            path: "{{ item.host_path }}"
            state: directory
            mode: '0777'
          become: true # incase the dirs are created at root level
          loop: "{{ charts.services.sonarr.persistence }}"
        - name: Set facts
          set_fact:
            helm_common_persistence_shows: >-
              {{- helm_common_persistence_shows | default('')
                  + 'persistence.shows-' + item.name + '.enabled=true,'
                  + 'persistence.shows-' + item.name + '.type=hostPath,'
                  + 'persistence.shows-' + item.name + '.hostPath=' +  item.host_path + ','
                  + 'persistence.shows-' + item.name + '.mountPath=/data/' + item.name + '/shows,'
              -}}
          loop: "{{ charts.services.sonarr.persistence }}"

    - name: Process variable to add disks
      block:
        - name: "Create host path dir"
          file:
            path: "{{ item.host_path }}"
            state: directory
            mode: '0777'
          become: true # incase the dirs are created at root level
          loop: "{{ charts.services.readarr.persistence }}"
        - name: Set facts
          set_fact:
            helm_common_persistence_books: >-
              {{- helm_common_persistence_books | default('')
                  + 'persistence.books-' + item.name + '.enabled=true,'
                  + 'persistence.books-' + item.name + '.type=hostPath,'
                  + 'persistence.books-' + item.name + '.hostPath=' +  item.host_path + ','
                  + 'persistence.books-' + item.name + '.mountPath=/data/' + item.name + '/books,'
              -}}
          loop: "{{ charts.services.readarr.persistence }}"

    - name: Process variable to add disks
      block:
        - name: "Create host path dir"
          file:
            path: "{{ item.host_path }}"
            state: directory
            mode: '0777'
          become: true # incase the dirs are created at root level
          loop: "{{ charts.services.lidarr.persistence }}"
        - name: Set facts
          set_fact:
            helm_common_persistence_music: >-
              {{- helm_common_persistence_music | default('')
                  + 'persistence.music-' + item.name + '.enabled=true,'
                  + 'persistence.music-' + item.name + '.type=hostPath,'
                  + 'persistence.music-' + item.name + '.hostPath=' +  item.host_path + ','
                  + 'persistence.music-' + item.name + '.mountPath=/data/' + item.name + '/music,'
              -}}
          loop: "{{ charts.services.lidarr.persistence }}"

    - name: Process variable to add disks
      block:
        - name: "Create host path dir"
          file:
            path: "{{ item.host_path }}"
            state: directory
            mode: '0777'
          become: true # incase the dirs are created at root level
          loop: "{{ charts.services.qbittorrent.persistence }}"
        - name: Set facts
          set_fact:
            helm_common_persistence_downloads: >-
              {{- helm_common_persistence_downloads | default('')
                  + 'persistence.downloads-' + item.name + '.enabled=true,'
                  + 'persistence.downloads-' + item.name + '.type=hostPath,'
                  + 'persistence.downloads-' + item.name + '.hostPath=' +  item.host_path + ','
                  + 'persistence.downloads-' + item.name + '.mountPath=/data/' + item.name + '/downloads,'
              -}}
          loop: "{{ charts.services.qbittorrent.persistence }}"

    - name: Install rancher local-path-provisioner
      when: charts.services.local_path_provisioner.enabled
      block:
      - name: apply manifests
        shell: "kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/{{ charts.services.local_path_provisioner.version }}/deploy/local-path-storage.yaml"

      - name: set default storage class
        shell: "kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'"

    - name: Install ingress-nginx
      # https://github.com/kubernetes/ingress-nginx/blob/main/docs/deploy/index.md#quick-start
      # https://github.com/kubernetes/ingress-nginx/blob/main/docs/deploy/baremetal.md#over-a-nodeport-service
      when: charts.services.ingress_nginx.enabled
      block:
      - name: Install/Upgrade the ingress-nginx chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: nginx-ingress
          repo_link: https://kubernetes.github.io/ingress-nginx
          install_namespace: "{{ namespace_ingress }}"
          timeout: "{{ charts.timeout }}"
          release_name: ingress-nginx
          chart_name: ingress-nginx
          version: "{{ charts.services.ingress_nginx.version }}"
          # setting proxy-body-size=0 disables size checks for uploads and sets
          # it as the default for all ingresses handled by this controller
          #   https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#custom-max-body-size   
          #   https://nginx.org/en/docs/http/ngx_http_core_module.html#client_max_body_size
          #   https://github.com/kubernetes/ingress-nginx/blob/main/docs/user-guide/nginx-configuration/configmap.md#proxy-body-size
          set_options: "--set \
            controller.config.proxy-body-size=0,\
            controller.service.type=NodePort,\
            controller.service.nodePorts.http=30080,\
            controller.service.nodePorts.https=30443,\
            controller.service.externalTrafficPolicy=Local"
    
    - name: Install cert-manager
      # https://cert-manager.io/docs/installation/helm/
      # https://cert-manager.io/docs/tutorials/acme/nginx-ingress/
      when: charts.services.cert_manager.enabled
      block:
      - name: Install/Upgrade the cert-manager chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: jetstack
          repo_link: https://charts.jetstack.io
          install_namespace: "{{ namespace_cert_manager }}"
          timeout: "{{ charts.timeout }}"
          release_name: cert-manager
          chart_name: cert-manager
          version: "{{ charts.services.cert_manager.version }}"
          set_options: "--set \
            ingressShim.defaultIssuerName=letsencrypt-prod,\
            prometheus.enabled=true,\
            crds.keep=false,\
            crds.enabled=true"

      - name: "install clusterissuer CR with account email: {{ charts.services.cert_manager.email }}"
        shell: |
          kubectl apply -f - <<EOF
            apiVersion: cert-manager.io/v1
            kind: ClusterIssuer
            metadata:
              name: letsencrypt-prod
              namespace: {{ namespace_cert_manager }}
            spec:
              acme:
                # The ACME server URL
                server: https://acme-v02.api.letsencrypt.org/directory
                # Email address used for ACME registration
                email: "{{ charts.services.cert_manager.email }}"
                # Name of a secret used to store the ACME account private key
                privateKeySecretRef:
                  name: letsencrypt-prod
                # Enable the HTTP-01 challenge provider
                solvers:
                  - http01:
                      ingress:
                        ingressClassName: nginx
          EOF

    - name: Install loki-stack
      when: charts.services.loki_stack.enabled
      block:
      - name: Install/Upgrade the loki-stack chart
        include_tasks: tasks-install-chart.yaml
        # https://artifacthub.io/packages/helm/grafana/loki-stack
        vars:
          repo_name: grafana
          repo_link: https://grafana.github.io/helm-charts
          install_namespace: "{{ namespace_monitoring }}"
          timeout: "{{ charts.timeout }}"
          release_name: loki-stack
          chart_name: loki-stack
          version: "{{ charts.services.loki_stack.version }}"
          set_options: "--set \
            loki.isDefault=False,\
            test_pod.enable=False,\
            fluent-bit.enabled=True,\
            promtail.enabled=False"

      - name: Set config for Grafana to add Loki as a data source
        set_fact:
          helm_kube_prometheus_stack_loki_config: "\
            grafana.additionalDataSources[0].name=Loki,\
            grafana.additionalDataSources[0].type=loki,\
            grafana.additionalDataSources[0].access=proxy,\
            grafana.additionalDataSources[0].isDefault=False,\
            grafana.additionalDataSources[0].url='http://loki-stack.{{ namespace_monitoring }}:3100',"

    - name: Install kube-prometheus-stack
      when: charts.services.kube_prometheus_stack.enabled
      block:
      - name: Install/Upgrade the kube-prometheus-stack chart
        include_tasks: tasks-install-chart.yaml
        # https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
        vars:
          repo_name: prometheus-community
          repo_link: https://prometheus-community.github.io/helm-charts
          install_namespace: "{{ namespace_monitoring }}"
          timeout: "{{ charts.timeout }}"
          release_name: kube-prometheus-stack
          chart_name: kube-prometheus-stack
          version: "{{ charts.services.kube_prometheus_stack.version }}"
          set_options: "--set \
            {{ helm_kube_prometheus_stack_loki_config }}\
            prometheus.prometheusSpec.retention={{ charts.services.kube_prometheus_stack.prometheus.retention }},\
            prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.accessModes={'ReadWriteOnce'},\
            prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage='50Gi',\
            prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false,\
            prometheus.prometheusSpec.serviceMonitorNamespaceSelector=null,\
            prometheus.prometheusSpec.serviceMonitorSelector=null,\
            prometheus.prometheusSpec.ruleSelectorNilUsesHelmValues=false,\
            prometheus.prometheusSpec.ruleNamespaceSelector=null,\
            prometheus.prometheusSpec.ruleSelector=null,\
            prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues=false,\
            prometheus.prometheusSpec.podMonitorNamespaceSelector=null,\
            prometheus.prometheusSpec.podMonitorSelector=null,\
            prometheus.prometheusSpec.probeSelectorNilUsesHelmValues=false,\
            prometheus.prometheusSpec.probeSelectorNamespaceSelector=null,\
            prometheus.prometheusSpec.probeSelector=null,\
            prometheus.prometheusSpec.additionalScrapeConfigs[0].job_name=kubernetes-service-scraper,\
            prometheus.prometheusSpec.additionalScrapeConfigs[0].kubernetes_sd_configs[0].role=service,\
            prometheus.prometheusSpec.scrapeInterval={{ charts.services.kube_prometheus_stack.prometheus.scrape_interval }},\
            grafana.initChownData.enabled=false,\
            grafana.persistence.enabled=true,\
            grafana.adminUser={{ charts.services.kube_prometheus_stack.grafana.admin_username }},\
            grafana.adminPassword={{ charts.services.kube_prometheus_stack.grafana.admin_password }},\
            grafana.ingress.enabled=true,\
            grafana.ingress.annotations.cert-manager\\\\.io/cluster-issuer=letsencrypt-prod,\
            grafana.ingress.annotations.cert-manager\\\\.io/private-key-rotation-policy=Always,\
            grafana.ingress.tls[0].hosts[0]=grafana.{{ domain_name }},\
            grafana.ingress.tls[0].secretName=grafana-tls,\
            grafana.ingress.ingressClassName=nginx,\
            grafana.ingress.hosts[0]=grafana.{{ domain_name }}"

      - name: Search for all Pods labelled app.kubernetes.io/name=grafana
        vars:
          ansible_python_interpreter: "{{ venv_python }}"
        kubernetes.core.k8s_info:
          kind: Pod
          label_selectors:
            - app.kubernetes.io/name = grafana
        register: output

      - name: Install piechart panel plugin for Grafana
        vars:
          ansible_python_interpreter: "{{ venv_python }}"
        kubernetes.core.k8s_exec:
          namespace: "{{ namespace_monitoring }}"
          pod: "{{ output.resources[0].metadata.name }}"
          container: grafana
          command: grafana cli plugins install grafana-piechart-panel
        ignore_errors: True

      - name: Restart pods to pick up any config updates
        include_tasks: tasks-kubernetes-delete-kind-instances.yaml
        vars:
          kind: pod
          namespace: "{{ namespace_monitoring }}"
          contains: kube-prometheus-stack

      - debug:
          msg: >
            You can log into Grafana at 'grafana.{{ domain_name }}' using
            {{ charts.services.kube_prometheus_stack.grafana.admin_username }}/
            {{ charts.services.kube_prometheus_stack.grafana.admin_password }}

    - name: Install cnpg
      when: charts.services.cnpg.enabled
      block:
      - name: Install/Upgrade the cnpg chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: cnpg
          repo_link: https://cloudnative-pg.github.io/charts
          install_namespace: "{{ namespace_cloudnative_postgres }}"
          timeout: "{{ charts.timeout }}"
          release_name: cnpg
          chart_name: cloudnative-pg
          version: "{{ charts.services.cnpg.version }}"
          set_options: "--set \
            crds.create=true"

    - name: Install immich
      when: charts.services.immich.enabled
      block:
      - name: Install/Upgrade the immich chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: immich
          chart_name: immich
          version: "{{ charts.services.immich.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            immich.enable_ml={{ charts.services.immich.enable_ml }},\
            persistence.mlcache.enabled=true,\
            persistence.mlcache.type=hostPath,\
            persistence.mlcache.hostPath={{ charts.services.immich.host_path }}/mlcache,\
            persistence.microcache.enabled=true,\
            persistence.microcache.type=hostPath,\
            persistence.microcache.hostPath={{ charts.services.immich.host_path }}/microcache,\
            persistence.library.enabled=true,\
            persistence.library.type=hostPath,\
            persistence.library.hostPath={{ charts.services.immich.host_path }}/library,\
            persistence.uploads.enabled=true,\
            persistence.uploads.type=hostPath,\
            persistence.uploads.hostPath={{ charts.services.immich.host_path }}/uploads,\
            persistence.backups.enabled=true,\
            persistence.backups.type=hostPath,\
            persistence.backups.hostPath={{ charts.services.immich.host_path }}/backups,\
            persistence.thumbs.enabled=true,\
            persistence.thumbs.type=hostPath,\
            persistence.thumbs.hostPath={{ charts.services.immich.host_path }}/thumbs,\
            persistence.profile.enabled=true,\
            persistence.profile.type=hostPath,\
            persistence.profile.hostPath={{ charts.services.immich.host_path }}/profile,\
            persistence.video.enabled=true,\
            persistence.video.type=hostPath,\
            persistence.video.hostPath={{ charts.services.immich.host_path }}/encoded-video,\
            securityContext.container.runAsUser=0,\
            securityContext.container.privileged=true,\
            securityContext.container.runAsNonRoot=false,\
            securityContext.container.allowPrivilegeEscalation=true,\
            ingress.main.hosts[0].host='immich.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=immich,\
            ingress.main.hosts[0].paths[0].service.port=10323"

      - debug:
          msg: >
            You can log into Immich at 'immich.{{ domain_name }}'.

    - name: Install home-assistant
      when: charts.services.home_assistant.enabled
      block:
      - name: Install/Upgrade the home-assistant chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: home-assistant
          chart_name: home-assistant
          version: "{{ charts.services.home_assistant.version }}"
          # not incliuding config persistence as it impacts the init setup
          # specifically the trusted proxies dont get configured blocking
          # ingress access. This is because the configmaps cannot be mounted
          # at the expected location (subdir in the hostpath mount)
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_persistence_downloads }}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            homeassistant.trusted_proxies[0]='10.0.0.0/8',\
            ingress.main.hosts[0].host='home-assistant.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=home-assistant,\
            ingress.main.hosts[0].paths[0].service.port=8123"

    - name: Install jellyfin
      when: charts.services.jellyfin.enabled
      block:
      - name: Create config directory on hostpath for jellyfin
        file:
          path: "{{ charts.services.configs_dir }}/jellyfin"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the jellyfin chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: jellyfin
          chart_name: jellyfin
          version: "{{ charts.services.jellyfin.version }}"
          # to allow the pod to be able to use the /dev mount
          # to access /dev/dri/renderD128 for hwa, these options are set to true
          # - securityContext.container.runAsUser=0
          # - securityContext.container.privileged=true
          # - securityContext.container.allowPrivilegeEscalation=true
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_persistence_shows }}\
            {{ helm_common_persistence_movies }}\
            {{ helm_common_persistence_music }}\
            {{ helm_common_persistence_books }}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/jellyfin,\
            securityContext.container.runAsUser=0,\
            securityContext.container.privileged=true,\
            securityContext.container.runAsNonRoot=false,\
            securityContext.container.allowPrivilegeEscalation=true,\
            persistence.cache.enabled=true,\
            persistence.cache.accessMode=ReadWriteOnce,\
            persistence.cache.size=50G,\
            persistence.dev.enabled=true,\
            persistence.dev.type=hostPath,\
            persistence.dev.mountPath=/dev,\
            persistence.dev.hostPath=/dev,\
            ingress.main.hosts[0].host='jellyfin.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=jellyfin,\
            ingress.main.hosts[0].paths[0].service.port=8096"

      - debug:
          msg: >
            You can log into Jellyfin at 'jellyfin.{{ domain_name }}'.
            Data directories are available under '/data' and can be used by
            Jellyfin. If need be, delete any existing server and go to the
            URL mention above once again to setup a new server.

    - name: Install jellystat
      when: charts.services.jellystat.enabled
      block:
      - name: Install/Upgrade the jellystat chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: jellystat
          chart_name: jellystat
          version: "{{ charts.services.jellystat.version }}"
          # to allow the pod to be able to use the /dev mount
          # to access /dev/dri/renderD128 for hwa, these options are set to true
          # - securityContext.container.runAsUser=0
          # - securityContext.container.privileged=true
          # - securityContext.container.allowPrivilegeEscalation=true
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            ingress.main.hosts[0].host='jellystat.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=jellystat"

      - debug:
          msg: >
            You can log into jellystat at 'jellystat.{{ domain_name }}'.

    - name: Install qbittorrent
      when: charts.services.qbittorrent.enabled
      block:
      - name: Create config directory on hostpath for qbittorrent
        file:
          path: "{{ charts.services.configs_dir }}/qbittorrent"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the qbittorrent chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: qbittorrent
          chart_name: qbittorrent
          version: "{{ charts.services.qbittorrent.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_persistence_downloads }}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/qbittorrent,\
            ingress.main.hosts[0].host='qbittorrent.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=qbittorrent,\
            ingress.main.hosts[0].paths[0].service.port=10095"

      - name: Search for qbittorent pod
        vars:
          ansible_python_interpreter: "{{ venv_python }}"
        kubernetes.core.k8s_info:
          kind: Pod
          label_selectors:
            - app.kubernetes.io/instance = qbittorrent
            - app.kubernetes.io/name = qbittorrent
        register: output

      - name: Get randomly generated password from qbittorrent pod logs
        shell: "kubectl logs {{ output.resources[0].metadata.name }} | grep -i 'temporary password' | cut -d ':' -f 2 | tr -d ' '"
        register: qbittorrent_random_password

      - debug:
          msg: >
            You can log into qBittorrent at 'qbittorrent.{{ domain_name }}' using
            "admin/{{ qbittorrent_random_password.stdout }}" as the default creds.
            Change this after deployment. Downloads directory from the host is
            available under '/data' and can be used by the application to
            download things. Downloads in that directory will be relevant
            processing apps (like Radarr, Sonarr, etc if applicable).

    - name: Install flaresolverr
      when: charts.services.flaresolverr.enabled
      block:
      - name: Install/Upgrade the flaresolverr chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: flaresolverr
          chart_name: flaresolverr
          version: "{{ charts.services.flaresolverr.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_resources }},\
            persistence.config.enabled=false"

      - debug:
          msg: >
            You can flaresolverr to bypass Cloudflare's protection

    - name: Install prowlarr
      when: charts.services.prowlarr.enabled
      block:
      - name: Create config directory on hostpath for prowlarr
        file:
          path: "{{ charts.services.configs_dir }}/prowlarr"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the prowlarr chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: prowlarr
          chart_name: prowlarr
          version: "{{ charts.services.prowlarr.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/prowlarr,\
            ingress.main.hosts[0].host='prowlarr.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=prowlarr,\
            ingress.main.hosts[0].paths[0].service.port=9696"

      - debug:
          msg: >
            You can log into prowlarr at 'prowlarr.{{ domain_name }}'. Go to this
            URL and add the indexers you wish to use.

    - name: Install radarr
      when: charts.services.radarr.enabled
      block:
      - name: Create config directory on hostpath for radarr
        file:
          path: "{{ charts.services.configs_dir }}/radarr"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the radarr chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: radarr
          chart_name: radarr
          version: "{{ charts.services.radarr.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_persistence_movies }}\
            {{ helm_common_persistence_downloads }}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/radarr,\
            ingress.main.hosts[0].host='radarr.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=radarr,\
            ingress.main.hosts[0].paths[0].service.port=7878"

      - debug:
          msg: >
            You can log into radarr at 'radarr.{{ domain_name }}'.
            Data directories from the host are available under '/data' and
            can be used by the application to download things. Downloads in
            that directory will be picked up by Jellyfin.

    - name: Install sonarr
      when: charts.services.sonarr.enabled
      block:
      - name: Create config directory on hostpath for sonarr
        file:
          path: "{{ charts.services.configs_dir }}/sonarr"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the sonarr chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: sonarr
          chart_name: sonarr
          version: "{{ charts.services.sonarr.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_persistence_shows }}\
            {{ helm_common_persistence_downloads }}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/sonarr,\
            ingress.main.hosts[0].host='sonarr.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=sonarr,\
            ingress.main.hosts[0].paths[0].service.port=8989"

      - debug:
          msg: >
            You can log into sonarr at 'sonarr.{{ domain_name }}'.
            Data directories from the host are available under '/data' and
            can be used by the application to download things. Downloads in
            that directory will be picked up by Jellyfin.

    - name: Install tdarr
      when: charts.services.tdarr.enabled
      block:
      - name: Create config directory on hostpath for tdarr
        file:
          path: "{{ charts.services.configs_dir }}/tdarr"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the tdarr chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: tdarr
          chart_name: tdarr
          version: "{{ charts.services.tdarr.version }}"
          # For auth
          # https://docs.tdarr.io/docs/other/authentication
          # Setting PGID and PUID as this is used by Tdarr for all its
          # operations. Without setting this the "Copy Action" was failing
          # For API key
          # https://docs.tdarr.io/docs/installation/variables#tdarr-server-variables
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_persistence_shows }}\
            {{ helm_common_persistence_movies }}\
            {{ helm_common_persistence_cache }}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            securityContext.container.PUID=\"{{ uid }}\",\
            securityContext.container.PGID=\"568\",\
            workload.main.podSpec.containers.main.env.auth=true,\
            workload.main.podSpec.containers.main.env.seededApiKey={{ charts.services.tdarr.apiKey }},\
            workload.main.podSpec.containers.main.env.apiKey={{ charts.services.tdarr.apiKey }},\
            persistence.configs.enabled=true,\
            persistence.configs.type=hostPath,\
            persistence.configs.hostPath={{ charts.services.configs_dir }}/tdarr,\
            ingress.main.hosts[0].host='tdarr.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=tdarr,\
            ingress.main.hosts[0].paths[0].service.port=8265"

      - debug:
          msg: >
            You can log into tdarr at 'tdarr.{{ domain_name }}'.
            Data directories are available under '/data' and can be used by
            tdarr.

    - name: Install bazarr
      when: charts.services.bazarr.enabled
      block:
      - name: Create config directory on hostpath for bazarr
        file:
          path: "{{ charts.services.configs_dir }}/bazarr"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the bazarr chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: bazarr
          chart_name: bazarr
          version: "{{ charts.services.bazarr.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_persistence_shows }}\
            {{ helm_common_persistence_movies }}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/bazarr,\
            metrics.main.enabled=false,\
            ingress.main.hosts[0].host='bazarr.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=bazarr,\
            ingress.main.hosts[0].paths[0].service.port=6767"

      - debug:
          msg: >
            You can log into bazarr at 'bazarr.{{ domain_name }}'.
            Data directories from the host are available under '/data' and
            can be used by the application.

    - name: Install readarr
      when: charts.services.readarr.enabled
      block:
      - name: Create config directory on hostpath for readarr
        file:
          path: "{{ charts.services.configs_dir }}/readarr"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the readarr chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: readarr
          chart_name: readarr
          version: "{{ charts.services.readarr.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_persistence_books }}\
            {{ helm_common_persistence_downloads }}}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/readarr,\
            ingress.main.hosts[0].host='readarr.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=readarr,\
            ingress.main.hosts[0].paths[0].service.port=8787"

      - debug:
          msg: >
            You can log into readarr at 'readarr.{{ domain_name }}'.
            Data directories from the host are available under '/data' and
            can be used by the application.

    - name: Install lidarr
      when: charts.services.lidarr.enabled
      block:
      - name: Create config directory on hostpath for lidarr
        file:
          path: "{{ charts.services.configs_dir }}/lidarr"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the lidarr chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: lidarr
          chart_name: lidarr
          version: "{{ charts.services.lidarr.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_persistence_music }}\
            {{ helm_common_persistence_downloads }}}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/lidarr,\
            ingress.main.hosts[0].host='lidarr.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=lidarr,\
            ingress.main.hosts[0].paths[0].service.port=8686"

      - debug:
          msg: >
            You can log into lidarr at 'lidarr.{{ domain_name }}'.
            Data directories from the host are available under '/data' and
            can be used by the application.

    - name: Install ombi
      when: charts.services.ombi.enabled
      block:
      - name: Create config directory on hostpath for ombi
        file:
          path: "{{ charts.services.configs_dir }}/ombi"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the ombi chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: ombi
          chart_name: ombi
          version: "{{ charts.services.ombi.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/ombi,\
            ingress.main.hosts[0].host='ombi.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=ombi,\
            ingress.main.hosts[0].paths[0].service.port=3579"
      - debug:
          msg: >
            You can log into ombi at 'ombi.{{ domain_name }}'.
            Data directories are available under '/data' and can be used by
            ombi. If need be, delete any existing server and go to the
            URL mention above once again to setup a new server.

    - name: Install jellyseerr
      when: charts.services.jellyseerr.enabled
      block:
      - name: Create config directory on hostpath for jellyseerr
        file:
          path: "{{ charts.services.configs_dir }}/jellyseerr"
          state: directory
          mode: '0777'
        become: true

      - name: Install/Upgrade the jellyseerr chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: jellyseerr
          chart_name: jellyseerr
          version: "{{ charts.services.jellyseerr.version }}"
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_security_contexts }},\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/jellyseerr,\
            ingress.main.hosts[0].host='jellyseerr.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=jellyseerr,\
            ingress.main.hosts[0].paths[0].service.port=5055"
      - debug:
          msg: >
            You can log into jellyseerr at 'jellyseerr.{{ domain_name }}'.
            Data directories are available under '/data' and can be used by
            jellyseerr. If need be, delete any existing server and go to the
            URL mention above once again to setup a new server.

    - name: Install librespeed
      when: charts.services.librespeed.enabled
      block:
      - name: Install/Upgrade the librespeed chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: librespeed
          chart_name: librespeed
          version: "{{ charts.services.librespeed.version }}"
          # PUID={{ uid }} gives write access on the pod
          # 568 is the default user ID, added to the groups cause why not
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            {{ helm_common_persistence_config }},\
            persistence.config.hostPath={{ charts.services.configs_dir }}/librespeed,\
            securityContext.container.PUID=\"{{ uid }}\",\
            securityContext.container.PGID=\"568\",\
            ingress.main.hosts[0].host='librespeed.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=librespeed,\
            ingress.main.hosts[0].paths[0].service.port=10016"

      - debug:
          msg: >
            You can log into librespeed at 'librespeed.{{ domain_name }}'.

    - name: Install calibre-web
      when: charts.services.calibre_web.enabled
      block:
      - name: Install/Upgrade the calibre-web chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: calibre-web
          chart_name: calibre-web
          version: "{{ charts.services.calibre_web.version }}"
          # PUID={{ uid }} gives write access on the pod
          # 568 is the default user ID, added to the groups cause why not
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_persistence_books }}\
            {{ helm_common_persistence_downloads }}}\
            {{ helm_common_resources }},\
            {{ helm_common_ingress }},\
            securityContext.container.PUID=\"{{ uid }}\",\
            securityContext.container.PGID=\"568\",\
            ingress.main.hosts[0].host='calibre-web.{{ domain_name }}',\
            ingress.main.hosts[0].paths[0].service.name=calibre-web,\
            ingress.main.hosts[0].paths[0].service.port=8083"

      - debug:
          msg: >
            You can log into calibre-web at 'calibre-web.{{ domain_name }}'.
            Data directories from the host are available under '/data' and
            can be used by the application.

    - name: Install calibre
      when: charts.services.calibre.enabled
      block:
      - name: Install/Upgrade the calibre chart
        include_tasks: tasks-install-chart.yaml
        vars:
          repo_name: TrueCharts
          repo_link: oci://tccr.io/truecharts
          install_namespace: "{{ namespace_generic_services }}"
          timeout: "{{ charts.timeout }}"
          release_name: calibre
          chart_name: calibre
          version: "{{ charts.services.calibre.version }}"
          # PUID={{ uid }} gives write access on the pod
          # 568 is the default user ID, added to the groups cause why not
          # securityContext.container.seccompProfile.type is required for the
          # guacamole VNC client to be able to make sys calls (required )
          set_options: "--set \
            {{ helm_common_general }},\
            {{ helm_common_persistence }},\
            {{ helm_common_persistence_books }}\
            {{ helm_common_persistence_downloads }}}\
            {{ helm_common_resources }},\
            securityContext.container.PUID=\"{{ uid }}\",\
            securityContext.container.PGID=\"568\",\
            securityContext.container.seccompProfile.type=Unconfined,\
            service.main.type=NodePort,\
            service.main.ports.main.nodePort=30000,\
            service.webserver.enabled=true"

      - debug:
          msg: >
            You can log into calibre at '{{ ip }}:30000'.
            Data directories from the host are available under '/data' and
            can be used by the application.
